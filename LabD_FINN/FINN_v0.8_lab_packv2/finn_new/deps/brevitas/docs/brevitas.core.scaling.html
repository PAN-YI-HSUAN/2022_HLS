

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>brevitas.core.scaling package &mdash; Brevitas 0.2.0b1.dev0+gc32fb31.d20210127 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Brevitas
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">brevitas.core.scaling package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-brevitas.core.scaling.int_scaling">brevitas.core.scaling.int_scaling module</a></li>
<li><a class="reference internal" href="#module-brevitas.core.scaling.runtime">brevitas.core.scaling.runtime module</a></li>
<li><a class="reference internal" href="#module-brevitas.core.scaling.standalone">brevitas.core.scaling.standalone module</a></li>
<li><a class="reference internal" href="#module-brevitas.core.scaling">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Brevitas</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>brevitas.core.scaling package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/brevitas.core.scaling.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="brevitas-core-scaling-package">
<h1>brevitas.core.scaling package<a class="headerlink" href="#brevitas-core-scaling-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-brevitas.core.scaling.int_scaling">
<span id="brevitas-core-scaling-int-scaling-module"></span><h2>brevitas.core.scaling.int_scaling module<a class="headerlink" href="#module-brevitas.core.scaling.int_scaling" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="brevitas.core.scaling.int_scaling.IntScaling">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.core.scaling.int_scaling.</code><code class="sig-name descname">IntScaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">signed</span></em>, <em class="sig-param"><span class="n">narrow_range</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.int_scaling.IntScaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt id="brevitas.core.scaling.int_scaling.IntScaling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">bit_width</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.int_scaling.IntScaling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="brevitas.core.scaling.int_scaling.IntScaling.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#brevitas.core.scaling.int_scaling.IntScaling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="brevitas.core.scaling.int_scaling.PowerOfTwoIntScaling">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.core.scaling.int_scaling.</code><code class="sig-name descname">PowerOfTwoIntScaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">signed</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.int_scaling.PowerOfTwoIntScaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt id="brevitas.core.scaling.int_scaling.PowerOfTwoIntScaling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">bit_width</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.int_scaling.PowerOfTwoIntScaling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="brevitas.core.scaling.int_scaling.PowerOfTwoIntScaling.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#brevitas.core.scaling.int_scaling.PowerOfTwoIntScaling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-brevitas.core.scaling.runtime">
<span id="brevitas-core-scaling-runtime-module"></span><h2>brevitas.core.scaling.runtime module<a class="headerlink" href="#module-brevitas.core.scaling.runtime" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="brevitas.core.scaling.runtime.RuntimeStatsScaling">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.core.scaling.runtime.</code><code class="sig-name descname">RuntimeStatsScaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">scaling_stats_impl</span></em>, <em class="sig-param"><span class="n">scaling_stats_input_view_shape_impl</span></em>, <em class="sig-param"><span class="n">restrict_scaling_impl</span></em>, <em class="sig-param"><span class="n">scaling_shape</span></em>, <em class="sig-param"><span class="n">affine_rescaling</span></em>, <em class="sig-param"><span class="n">scaling_stats_permute_dims</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scaling_stats_momentum</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">scaling_min_val</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.runtime.RuntimeStatsScaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt id="brevitas.core.scaling.runtime.RuntimeStatsScaling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.runtime.RuntimeStatsScaling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="brevitas.core.scaling.runtime.RuntimeStatsScaling.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#brevitas.core.scaling.runtime.RuntimeStatsScaling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="brevitas.core.scaling.runtime.StatsFromParameterScaling">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.core.scaling.runtime.</code><code class="sig-name descname">StatsFromParameterScaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">scaling_stats_impl</span></em>, <em class="sig-param"><span class="n">scaling_stats_input_view_shape_impl</span></em>, <em class="sig-param"><span class="n">scaling_stats_input_concat_dim</span></em>, <em class="sig-param"><span class="n">tracked_parameter_list</span></em>, <em class="sig-param"><span class="n">restrict_scaling_impl</span></em>, <em class="sig-param"><span class="n">scaling_shape</span></em>, <em class="sig-param"><span class="n">affine_rescaling</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">scaling_min_val</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.runtime.StatsFromParameterScaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt id="brevitas.core.scaling.runtime.StatsFromParameterScaling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">ignored</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.runtime.StatsFromParameterScaling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="brevitas.core.scaling.runtime.StatsFromParameterScaling.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#brevitas.core.scaling.runtime.StatsFromParameterScaling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-brevitas.core.scaling.standalone">
<span id="brevitas-core-scaling-standalone-module"></span><h2>brevitas.core.scaling.standalone module<a class="headerlink" href="#module-brevitas.core.scaling.standalone" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="brevitas.core.scaling.standalone.ConstScaling">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.core.scaling.standalone.</code><code class="sig-name descname">ConstScaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">scaling_init</span></em>, <em class="sig-param"><span class="n">restrict_scaling_impl</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scaling_min_val</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.standalone.ConstScaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ScriptModule implementation of a constant scale factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scaling_init</strong> (<em>Union</em><em>[</em><em>float</em><em>, </em><em>Tensor</em><em>]</em>) – value to use as constant scale factor.</p></li>
<li><p><strong>restrict_scaling_impl</strong> (<em>Module</em>) – restrict scaling_init according to some criteria. Default: None</p></li>
<li><p><strong>scaling_min_val</strong> (<em>float</em>) – force a lower-bound on scaling_init. Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>scale factor wrapped in a float torch.tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span> <span class="o">=</span> <span class="n">ConstScaling</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">tensor(1.)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span> <span class="o">=</span> <span class="n">ConstScaling</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">scaling_min_val</span><span class="o">=</span><span class="mf">3.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">tensor(3.)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span> <span class="o">=</span> <span class="n">ConstScaling</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">restrict_scaling_impl</span><span class="o">=</span><span class="n">PowerOfTwoRestrictValue</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">tensor(4.)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The forward method accepts a single placeholder argument. This is required by (early versions of)
TorchScript to be consistent across different scaling implementations.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Maps to scaling_impl_type == ScalingImplType.CONST == ‘CONST’ == ‘const’ in higher-level APIs.</p>
</div>
<dl class="py method">
<dt id="brevitas.core.scaling.standalone.ConstScaling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">placeholder</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.standalone.ConstScaling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="brevitas.core.scaling.standalone.ConstScaling.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#brevitas.core.scaling.standalone.ConstScaling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="brevitas.core.scaling.standalone.ParameterFromRuntimeStatsScaling">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.core.scaling.standalone.</code><code class="sig-name descname">ParameterFromRuntimeStatsScaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">collect_stats_steps</span></em>, <em class="sig-param"><span class="n">scaling_stats_impl</span></em>, <em class="sig-param"><span class="n">scaling_stats_input_view_shape_impl</span><span class="o">=</span><span class="default_value">OverBatchOverTensorView()</span></em>, <em class="sig-param"><span class="n">scaling_shape</span><span class="o">=</span><span class="default_value">()</span></em>, <em class="sig-param"><span class="n">restrict_scaling_impl</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scaling_stats_permute_dims</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scaling_stats_momentum</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">scaling_min_val</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.standalone.ParameterFromRuntimeStatsScaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ScriptModule implementation of a learned scale factor initialized from runtime statistics.
The implementation works in two phases. During the first phase, statistics are collected in
the same fashion as batchnorm, meaning that while the module is in training mode a set of per-batch
statistics are computed and returned, while in background an exponential moving average of them
is retained and returned in inference mode. During the second phase, the moving average accumulated during the first
phase is used to initialize a learned torch.nn.Parameter, and then the behaviour is the same
as ParameterScaling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>collect_stats_steps</strong> (<em>int</em>) – Number of calls to the forward method in training mode to collect statistics for.</p></li>
<li><p><strong>scaling_stats_impl</strong> (<em>Module</em>) – Implementation of the statistics computed during the collection phase.</p></li>
<li><p><strong>scaling_stats_input_view_shape_impl</strong> (<em>Module</em>) – Implementation of the view applied to the runtime
input during the statistics collection phase. Default: OverBatchOverTensorView().</p></li>
<li><p><strong>scaling_shape</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>..</em><em>]</em>) – shape of the torch.nn.Parameter used in the second phase. Default: SCALAR_SHAPE.</p></li>
<li><p><strong>restrict_scaling_impl</strong> (<em>Module</em>) – restrict the learned scale factor according to some criteria. Default: None</p></li>
<li><p><strong>scaling_stats_permute_dims</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>, …]]) – Optional[Tuple[int, …]]: Permutation to apply to the runtime
input before going into scaling_stats_input_view_shape_impl. Default: None</p></li>
<li><p><strong>scaling_stats_momentum</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – float = Momentum for the statistics moving average. Default: DEFAULT_MOMENTUM.</p></li>
<li><p><strong>scaling_min_val</strong> (<em>float</em>) – force a lower-bound on the learned scale factor. Default: None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>learned scale factor wrapped in a float torch.tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – if scaling_shape != SCALAR_SHAPE and scaling_stats_permute_dims is None</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span> <span class="o">=</span> <span class="n">ParameterFromRuntimeStatsScaling</span><span class="p">(</span><span class="n">collect_stats_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scaling_stats_impl</span><span class="o">=</span><span class="n">AbsMax</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="o">.</span><span class="n">training</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">tensor(3.)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="go">tensor(3., grad_fn=&lt;AbsBinarySignGradFnBackward&gt;)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Set env variable BREVITAS_IGNORE_MISSING_KEYS=1 to avoid errors when retraining
from a floating point state dict.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Maps to scaling_impl_type == ScalingImplType.PARAMETER_FROM_STATS == ‘PARAMETER_FROM_STATS’
== ‘parameter_from_stats’ when applied to runtime values (inputs/outputs/activations) in higher-level APIs.</p>
</div>
<dl class="py method">
<dt id="brevitas.core.scaling.standalone.ParameterFromRuntimeStatsScaling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">stats_input</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.standalone.ParameterFromRuntimeStatsScaling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="brevitas.core.scaling.standalone.ParameterFromRuntimeStatsScaling.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#brevitas.core.scaling.standalone.ParameterFromRuntimeStatsScaling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="brevitas.core.scaling.standalone.ParameterScaling">
<em class="property">class </em><code class="sig-prename descclassname">brevitas.core.scaling.standalone.</code><code class="sig-name descname">ParameterScaling</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">scaling_init</span></em>, <em class="sig-param"><span class="n">scaling_shape</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">restrict_scaling_impl</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">scaling_min_val</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.standalone.ParameterScaling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ScriptModule implementation of a learned scale factor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scaling_init</strong> (<em>Union</em><em>[</em><em>float</em><em>, </em><em>Tensor</em><em>]</em>) – value to initialize the learned scale factor.</p></li>
<li><p><strong>scaling_shape</strong> (<em>Tuple</em><em>[</em><em>int</em><em>, </em><em>..</em><em>]</em>) – shape to extend a scalar float or tensor scaling_init. Default: None</p></li>
<li><p><strong>restrict_scaling_impl</strong> (<em>Module</em>) – restrict the learned scale factor according to some criteria. Default: None</p></li>
<li><p><strong>scaling_min_val</strong> (<em>float</em>) – force a lower-bound on the learned scale factor. Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>learned scale factor wrapped in a float torch.tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – if scaling_init is a non-scalar tensor and scaling_shape is != scaling_init.shape.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span> <span class="o">=</span> <span class="n">ParameterScaling</span><span class="p">(</span><span class="mf">6.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">tensor(6., grad_fn=&lt;AbsBinarySignGradFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span> <span class="o">=</span> <span class="n">ParameterScaling</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">scaling_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">tensor([6., 6., 6.], grad_fn=&lt;AbsBinarySignGradFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span> <span class="o">=</span> <span class="n">ParameterScaling</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="n">scaling_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">restrict_scaling_impl</span><span class="o">=</span><span class="n">PowerOfTwoRestrictValue</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaling_impl</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="go">tensor([8., 8., 8.], grad_fn=&lt;PowBackward1&gt;)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Set env variable BREVITAS_IGNORE_MISSING_KEYS=1 to avoid errors when retraining
from a floating point state dict.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The forward method accepts a single placeholder argument. This is required by (early versions of)
TorchScript to be consistent across different scaling implementations.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Maps to scaling_impl_type == ScalingImplType.PARAMETER == ‘PARAMETER’ == ‘parameter’ in higher-level APIs.</p>
</div>
<dl class="py method">
<dt id="brevitas.core.scaling.standalone.ParameterScaling.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">placeholder</span></em><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.core.scaling.standalone.ParameterScaling.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="brevitas.core.scaling.standalone.ParameterScaling.training">
<code class="sig-name descname">training</code><em class="property">: bool</em><a class="headerlink" href="#brevitas.core.scaling.standalone.ParameterScaling.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-brevitas.core.scaling">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-brevitas.core.scaling" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - Xilinx, Inc.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>